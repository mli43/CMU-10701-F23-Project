{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1cf2774",
   "metadata": {},
   "source": [
    "# Reference: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954c4a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4591c9",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9def3088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3690521717071533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>another easily recognizable form of ar technol...</td>\n",
       "      <td>une autre forme connue de ra est l ecran de vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>however since sao paulo is a big and scattered...</td>\n",
       "      <td>cependant comme sao paulo est une grande ville...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this provision provides among other things tha...</td>\n",
       "      <td>cette provision prevoit notamment qu une deduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where would you expect to find a document that...</td>\n",
       "      <td>ou crois tu que tu trouveras un document qui t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at the request of agency staff additional comm...</td>\n",
       "      <td>a la demande du personnel de l office royal a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  another easily recognizable form of ar technol...   \n",
       "1  however since sao paulo is a big and scattered...   \n",
       "2  this provision provides among other things tha...   \n",
       "3  where would you expect to find a document that...   \n",
       "4  at the request of agency staff additional comm...   \n",
       "\n",
       "                                                  fr  \n",
       "0  une autre forme connue de ra est l ecran de vi...  \n",
       "1  cependant comme sao paulo est une grande ville...  \n",
       "2  cette provision prevoit notamment qu une deduc...  \n",
       "3  ou crois tu que tu trouveras un document qui t...  \n",
       "4  a la demande du personnel de l office royal a ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "if os.path.isfile('./data/valid_subset.csv'):\n",
    "    # cleaned, filtered by length, 10% dataset\n",
    "    df = pd.read_csv('./data/valid_subset.csv', index_col=False)\n",
    "    \n",
    "elif os.path.isfile('./data/valid_cleaned_data.csv'):\n",
    "    # cleaned, filtered by length dataset\n",
    "    df = pd.read_csv('./data/valid_cleaned_data.csv', index_col=False)\n",
    "    \n",
    "elif os.path.isfile('./data/cleaned_data.csv'):\n",
    "    # cleaned dataset\n",
    "    df = pd.read_csv('./data/cleaned_data.csv', index_col=False)\n",
    "else:\n",
    "\n",
    "    df = pd.read_csv('./data/en-fr.csv')\n",
    "\n",
    "end = time.time()\n",
    "display(end - start)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a32d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146993 entries, 0 to 146992\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   en      146993 non-null  object\n",
      " 1   fr      146993 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488d018",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5554f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67252ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02051687240600586"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean data only if not available    \n",
    "\n",
    "start = time.time()\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "if not os.path.isfile('./data/cleaned_data.csv'):\n",
    "    df['en'] = df['en'].apply(lambda x: normalizeString(str(x)))\n",
    "    df['fr'] = df['fr'].apply(lambda x: normalizeString(str(x)))\n",
    "    df.to_csv('./data/cleaned_data.csv', index=False)\n",
    "    \n",
    "end = time.time()\n",
    "display(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35c2c74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>another easily recognizable form of ar technol...</td>\n",
       "      <td>une autre forme connue de ra est l ecran de vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>however since sao paulo is a big and scattered...</td>\n",
       "      <td>cependant comme sao paulo est une grande ville...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this provision provides among other things tha...</td>\n",
       "      <td>cette provision prevoit notamment qu une deduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where would you expect to find a document that...</td>\n",
       "      <td>ou crois tu que tu trouveras un document qui t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at the request of agency staff additional comm...</td>\n",
       "      <td>a la demande du personnel de l office royal a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146988</th>\n",
       "      <td>it would be most beneficial and effective for ...</td>\n",
       "      <td>il serait tres avantageux et efficace pour le ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146989</th>\n",
       "      <td>cost reductions particular importance shall be...</td>\n",
       "      <td>reductions des couts une importance particulie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146990</th>\n",
       "      <td>this inconsistent approach to marking had sign...</td>\n",
       "      <td>cette methode de cotation non uniforme a eu de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146991</th>\n",
       "      <td>testimony of lgen gervais transcripts vol</td>\n",
       "      <td>temoignage du lgne gervais transcriptions vol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146992</th>\n",
       "      <td>a reinsurance agreement between the fcic and t...</td>\n",
       "      <td>l accord de reassurance entre la fcic et les c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146993 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       en  \\\n",
       "0       another easily recognizable form of ar technol...   \n",
       "1       however since sao paulo is a big and scattered...   \n",
       "2       this provision provides among other things tha...   \n",
       "3       where would you expect to find a document that...   \n",
       "4       at the request of agency staff additional comm...   \n",
       "...                                                   ...   \n",
       "146988  it would be most beneficial and effective for ...   \n",
       "146989  cost reductions particular importance shall be...   \n",
       "146990  this inconsistent approach to marking had sign...   \n",
       "146991          testimony of lgen gervais transcripts vol   \n",
       "146992  a reinsurance agreement between the fcic and t...   \n",
       "\n",
       "                                                       fr  \n",
       "0       une autre forme connue de ra est l ecran de vi...  \n",
       "1       cependant comme sao paulo est une grande ville...  \n",
       "2       cette provision prevoit notamment qu une deduc...  \n",
       "3       ou crois tu que tu trouveras un document qui t...  \n",
       "4       a la demande du personnel de l office royal a ...  \n",
       "...                                                   ...  \n",
       "146988  il serait tres avantageux et efficace pour le ...  \n",
       "146989  reductions des couts une importance particulie...  \n",
       "146990  cette methode de cotation non uniforme a eu de...  \n",
       "146991      temoignage du lgne gervais transcriptions vol  \n",
       "146992  l accord de reassurance entre la fcic et les c...  \n",
       "\n",
       "[146993 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Filter dataset by length\n",
    "MAX_LENGTH = 35\n",
    "\n",
    "if not os.path.isfile('./data/valid_cleaned_data.csv'):\n",
    "    df['en_len'] = df['en'].apply(lambda sent: len(sent.split(\" \")))\n",
    "    df['fr_len'] = df['fr'].apply(lambda sent: len(sent.split(\" \")))\n",
    "\n",
    "    df = df[df['en_len'] < MAX_LENGTH]\n",
    "    df = df[df['fr_len'] < MAX_LENGTH]\n",
    "    \n",
    "    df = df[['en', 'fr']]\n",
    "    \n",
    "    df.to_csv('./data/valid_cleaned_data.csv', index=False)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7757d5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146993 entries, 0 to 146992\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   en      146993 non-null  object\n",
      " 1   fr      146993 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "### Prepare only subset of data\n",
    "frac = 0.1\n",
    "\n",
    "if not os.path.isfile('./data/valid_subset.csv'):\n",
    "    df_subset = df.sample(frac=frac)\n",
    "    df_subset.to_csv('./data/valid_subset.csv', index=False)\n",
    "else:\n",
    "    df_subset = df\n",
    "\n",
    "df_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08378580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [en, fr]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset[df_subset.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b045139",
   "metadata": {},
   "source": [
    "## Create helpers to construct vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc0fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e729fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146993"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b50e5",
   "metadata": {},
   "source": [
    "## Preparing Data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "995d6416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14699/14699 [00:00<00:00, 26310.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6491856575012207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gc.collect()\n",
    "df_subset = df_subset.sample(frac=0.1)\n",
    "\n",
    "\n",
    "def prepareData(df):\n",
    "    en_lang = Lang('en')\n",
    "    fr_lang = Lang('fr')\n",
    "    \n",
    "    en_vocab = []\n",
    "    fr_vocab = []\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], position=0, leave=True):\n",
    "        en_sent = row['en']\n",
    "        fr_sent = row['fr']\n",
    "        \n",
    "        en_vocab += en_sent.split(\" \")\n",
    "        fr_vocab += fr_sent.split(\" \")\n",
    "        \n",
    "    \n",
    "    # Construct word2index and index2word dicts for the two languages\n",
    "    en_vocab = set(en_vocab)\n",
    "    fr_vocab = set(fr_vocab)\n",
    "    \n",
    "    en_word2index = dict([(word, i+3) for i, word in enumerate(en_vocab)])\n",
    "    fr_word2index = dict([(word, i+3) for i, word in enumerate(fr_vocab)])\n",
    "    \n",
    "    en_index2word = {v: k for k, v in en_word2index.items()}\n",
    "    fr_index2word = {v: k for k, v in fr_word2index.items()}\n",
    "    \n",
    "    en_lang.word2index = en_word2index\n",
    "    fr_lang.word2index = fr_word2index\n",
    "    \n",
    "    en_lang.index2word.update(en_index2word)\n",
    "    fr_lang.index2word.update(fr_index2word)\n",
    "    \n",
    "    en_lang.n_words = len(en_lang.index2word.keys())\n",
    "    fr_lang.n_words = len(fr_lang.index2word.keys())\n",
    "    \n",
    "    return en_lang, fr_lang\n",
    "        \n",
    "\n",
    "start = time.time()\n",
    "en_lang, fr_lang = prepareData(df_subset)\n",
    "end = time.time() \n",
    "display(end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dd28a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a provisional time schedule for the consultati...</td>\n",
       "      <td>on trouvera au tableau ci apres un calendrier ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>date of compliance specified in notice of defa...</td>\n",
       "      <td>date du delai specifiee dans l avis de defaut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elizabeth leboe return to intermediate lesson ...</td>\n",
       "      <td>retour a la page des plans de lecon niveau int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the parks canada agency does not have the auth...</td>\n",
       "      <td>or l agence parcs canada n a pas le pouvoir de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>within the context of the government s securit...</td>\n",
       "      <td>assurer la securite des canadiens dans le cadr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>today in the city of winnipeg and all across m...</td>\n",
       "      <td>aujourd hui a winnipeg et partout dans ma prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>this hearing was convened by teleconference</td>\n",
       "      <td>l audience a eu lieu par teleconference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>normally he would have needed only hours to qu...</td>\n",
       "      <td>normalement il aurait eu besoin de heures seul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3673</th>\n",
       "      <td>transport canada has the lead role for policy ...</td>\n",
       "      <td>transports canada joue un role de premier plan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3674</th>\n",
       "      <td>assessment site audit design barrier free</td>\n",
       "      <td>evaluation verification du site conception acc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     en  \\\n",
       "0     a provisional time schedule for the consultati...   \n",
       "1     date of compliance specified in notice of defa...   \n",
       "2     elizabeth leboe return to intermediate lesson ...   \n",
       "3     the parks canada agency does not have the auth...   \n",
       "4     within the context of the government s securit...   \n",
       "...                                                 ...   \n",
       "3670  today in the city of winnipeg and all across m...   \n",
       "3671        this hearing was convened by teleconference   \n",
       "3672  normally he would have needed only hours to qu...   \n",
       "3673  transport canada has the lead role for policy ...   \n",
       "3674          assessment site audit design barrier free   \n",
       "\n",
       "                                                     fr  \n",
       "0     on trouvera au tableau ci apres un calendrier ...  \n",
       "1     date du delai specifiee dans l avis de defaut ...  \n",
       "2     retour a la page des plans de lecon niveau int...  \n",
       "3     or l agence parcs canada n a pas le pouvoir de...  \n",
       "4     assurer la securite des canadiens dans le cadr...  \n",
       "...                                                 ...  \n",
       "3670  aujourd hui a winnipeg et partout dans ma prov...  \n",
       "3671            l audience a eu lieu par teleconference  \n",
       "3672  normalement il aurait eu besoin de heures seul...  \n",
       "3673  transports canada joue un role de premier plan...  \n",
       "3674  evaluation verification du site conception acc...  \n",
       "\n",
       "[3675 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_subset.sample(frac=0.75)\n",
    "\n",
    "df_test = pd.concat([df_subset, df_train])\n",
    "df_test.drop_duplicates(keep=False, inplace=True)\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "df_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4de2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def get_dataloader(batch_size, en_lang, fr_lang, df):\n",
    "    \n",
    "    n = len(df)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    \n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=n, position=0, leave=True):\n",
    "        en_sent = row[en_lang.name]\n",
    "        fr_sent = row[fr_lang.name]\n",
    "        \n",
    "        en_ids = indexesFromSentence(en_lang, en_sent)\n",
    "        fr_ids = indexesFromSentence(fr_lang, fr_sent)\n",
    "                \n",
    "        en_ids.append(EOS_token)\n",
    "        fr_ids.append(EOS_token)\n",
    "        \n",
    "        input_ids[idx, :len(en_ids)] = en_ids\n",
    "        target_ids[idx, :len(fr_ids)] = fr_ids\n",
    "        \n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) #, num_workers=8)\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4dd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "887c945e",
   "metadata": {},
   "source": [
    "## Building LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fb4d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.LSTM = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.dropout(self.embedding(input).view(1,1,-1))\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output, hidden = self.LSTM(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        # shape = [num_lstm_layers, batch_size, hidden_size]\n",
    "        encoder_state = [torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
    "                              torch.zeros(1, batch_size, self.hidden_size, device=device)]\n",
    "        \n",
    "        return encoder_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08c0e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.LSTM = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output, (h_n, c_n) = self.LSTM(output, hidden)\n",
    "        output = self.out(output[0])\n",
    "        return output, (h_n, c_n)\n",
    "    \n",
    "    def initHidden(self):\n",
    "        \"\"\"\n",
    "        The spesific type of the hidden layer for the RNN type that is used (LSTM).\n",
    "        :return: All zero hidden state.\n",
    "        \"\"\"\n",
    "        return [torch.zeros(1, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(1, 1, self.hidden_size, device=device)]\n",
    "\n",
    "    def forward_old(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.LSTM(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ab26e7",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd1d7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(input_tensor, target_tensor, encoder, decoder, \n",
    "                encoder_optimizer, decoder_optimizer, criterion, is_training=True):\n",
    "    \n",
    "\n",
    "\n",
    "    batch = input_tensor.shape[0]\n",
    "\n",
    "    encoder_hiddens_last = []\n",
    "    loss = 0\n",
    "\n",
    "    for step_idx in range(batch):\n",
    "        encoder_hidden = encoder.initHidden(1)\n",
    "        input_tensor_step = input_tensor[step_idx, :][input_tensor[step_idx, :] != 0]\n",
    "        input_length = input_tensor_step.size(0)\n",
    "\n",
    "        encoder_outputs = torch.zeros(batch, MAX_LENGTH, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor_step[ei], encoder_hidden)\n",
    "            encoder_outputs[step_idx, ei, :] = encoder_output[0, 0]\n",
    "\n",
    "        # only return the hidden and cell states for the last layer and pass it to the decoder\n",
    "        hn, cn = encoder_hidden\n",
    "        encoder_hn_last_layer = hn[-1].view(1,1,-1)\n",
    "        encoder_cn_last_layer = cn[-1].view(1,1,-1)\n",
    "        encoder_hidden = [encoder_hn_last_layer, encoder_cn_last_layer]\n",
    "\n",
    "        if hn.shape[-1] != hidden_size:\n",
    "            print(hn.size)\n",
    "        if cn.shape[-1] != hidden_size:\n",
    "            print(cn.size)\n",
    "            break\n",
    "        encoder_hiddens_last.append(encoder_hidden)\n",
    "\n",
    "    if hn.shape[-1] != hidden_size:\n",
    "        print(f\"hn size {hn.shape[-1]} != hidden_size {hidden_size} \")\n",
    "        return \n",
    "    if cn.shape[-1] != hidden_size:\n",
    "        print(f\"hn size {cn.shape[-1]} != hidden_size {hidden_size} \")\n",
    "        return \n",
    "        \n",
    "\n",
    "    decoder_input = torch.tensor([SOS_token], device=device)\n",
    "    decoder_hiddens = encoder_hiddens_last\n",
    "    \n",
    "    if is_training:\n",
    "        # Training: target tensor available\n",
    "\n",
    "        for step_idx in range(batch):\n",
    "            # reset the LSTM hidden state. Must be done before you run a new sequence. Otherwise the LSTM will treat\n",
    "            # the new input sequence as a continuation of the previous sequence\n",
    "\n",
    "            target_tensor_step = target_tensor[step_idx, :][target_tensor[step_idx, :] != 0]\n",
    "            target_length = target_tensor_step.size(0)\n",
    "            decoder_hidden = decoder_hiddens[step_idx]\n",
    "\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "                # decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                #     decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "                loss += criterion(decoder_output, target_tensor_step[di].view(1)) / target_length\n",
    "                decoder_input = target_tensor_step[di]  # Teacher forcing\n",
    "    \n",
    "    else:\n",
    "        # Testing: target tensor not available \n",
    "        for step_idx in range(batch):\n",
    "            # reset the LSTM hidden state. Must be done before you run a new sequence. Otherwise the LSTM will treat\n",
    "            # the new input sequence as a continuation of the previous sequence\n",
    "\n",
    "            target_tensor_step = target_tensor[step_idx, :]\n",
    "            target_length = target_tensor_step[target_tensor_step != 0].size(0)\n",
    "            decoder_hidden = decoder_hiddens[step_idx]\n",
    "\n",
    "            for di in range(MAX_LENGTH):\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                loss += criterion(decoder_output, target_tensor_step[di].view(1)) / target_length\n",
    "\n",
    "                if decoder_input.item() == EOS_token:\n",
    "                    break\n",
    "\n",
    "\n",
    "    loss = loss / batch\n",
    "    \n",
    "    return loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ced0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    batch_bar   = tqdm(total=len(dataloader), dynamic_ncols=True, leave=True, position=0, desc='Train')\n",
    "    \n",
    "    for i, data in enumerate(dataloader):\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        input_tensor, target_tensor = data\n",
    "        \n",
    "        if device == torch.device(\"cuda\"):\n",
    "                input_tensor = input_tensor.cuda()\n",
    "                target_tensor = target_tensor.cuda()\n",
    "        \n",
    "        loss = train_batch(input_tensor, target_tensor, encoder, decoder, \n",
    "                encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        batch_bar.set_postfix(train_loss=\"{:.04f}\".format(float(total_loss / (i + 1))))\n",
    "        batch_bar.update()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "learning_rate = 0.01\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "encoder = EncoderRNN(en_lang.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, fr_lang.n_words).to(device)\n",
    "\n",
    "encoder_optimizer = optim.AdamW(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.AdamW(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "encoder_scheduler = optim.lr_scheduler.StepLR(encoder_optimizer, step_size=1, gamma=0.95)\n",
    "decoder_scheduler = optim.lr_scheduler.StepLR(decoder_optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_epoch(train_loader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd7b26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(dataloader, encoder, decoder, criterion):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    total_loss = 0\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, leave=True, position=0, desc='Test')\n",
    "    \n",
    "    for i, data in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            input_tensor, target_tensor = data\n",
    "                    \n",
    "            if device == torch.device(\"cuda\"):\n",
    "                    input_tensor = input_tensor.cuda()\n",
    "                    target_tensor = target_tensor.cuda()\n",
    "\n",
    "            loss = train_batch(input_tensor, target_tensor, encoder, decoder, \n",
    "                    encoder_optimizer, decoder_optimizer, criterion, is_training=False)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        batch_bar.set_postfix(test_loss=\"{:.04f}\".format(float(total_loss / (i + 1))))\n",
    "        batch_bar.update()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9256d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 230/230 [01:07<00:00,  3.39it/s, test_loss=13.4483]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.448340113266655"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "test_epoch(test_loader, encoder, decoder, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c079af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e05e9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, test_dataloader, encoder, decoder, n_epochs,\n",
    "          encoder_optimizer, decoder_optimizer, encoder_scheduler, decoder_scheduler,\n",
    "          criterion):\n",
    "    \n",
    "    start = time.time()\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f\"Epoch {epoch} / {n_epochs}\")\n",
    "        \n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        test_loss = test_epoch(test_dataloader, encoder, decoder, criterion)\n",
    "        \n",
    "        train_losses.append(loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "\n",
    "        encoder_scheduler.step()\n",
    "        decoder_scheduler.step()\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"encoder lr = {encoder_scheduler.get_last_lr()}, decoder lr = {decoder_scheduler.get_last_lr()}\")\n",
    "            print('%s (%d %d%%)' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100))\n",
    "\n",
    "    showPlot(train_losses)\n",
    "    showPlot(test_losses)\n",
    "    \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90ed2a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bac1a7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11024/11024 [00:00<00:00, 18840.98it/s]\n",
      "100%|██████████| 3675/3675 [00:00<00:00, 15214.81it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = get_dataloader(batch_size, en_lang, fr_lang, df_train)\n",
    "test_loader = get_dataloader(batch_size, en_lang, fr_lang, df_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa743bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20007,  6394, 13133, 16539,  2625,     2,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f079f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "learning_rate = 0.01\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "encoder = EncoderRNN(en_lang.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, fr_lang.n_words).to(device)\n",
    "\n",
    "encoder_optimizer = optim.AdamW(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.AdamW(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "encoder_scheduler = optim.lr_scheduler.StepLR(encoder_optimizer, step_size=1, gamma=0.95)\n",
    "decoder_scheduler = optim.lr_scheduler.StepLR(decoder_optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40740989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 689/689 [08:23<00:00,  1.37it/s, train_loss=6.4966]\n",
      "Test: 100%|██████████| 230/230 [01:07<00:00,  3.39it/s, test_loss=10.2519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 689/689 [08:25<00:00,  1.36it/s, train_loss=5.3924]\n",
      "Test: 100%|██████████| 230/230 [01:02<00:00,  3.66it/s, test_loss=8.8360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 689/689 [08:25<00:00,  1.36it/s, train_loss=4.6834]\n",
      "Test: 100%|██████████| 230/230 [01:00<00:00,  3.81it/s, test_loss=9.2087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 689/689 [08:23<00:00,  1.37it/s, train_loss=4.1278]\n",
      "Test: 100%|██████████| 230/230 [01:03<00:00,  3.63it/s, test_loss=11.1408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 689/689 [08:22<00:00,  1.37it/s, train_loss=3.7004]\n",
      "Test: 100%|██████████| 230/230 [01:05<00:00,  3.53it/s, test_loss=11.9405]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder lr = [0.007737809374999999], decoder lr = [0.007737809374999999]\n",
      "47m 19s (- 0m 0s) (5 100%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "train_losses, test_losses = train(train_loader, test_loader, encoder, decoder, epochs,\n",
    "                                 encoder_optimizer, decoder_optimizer,\n",
    "                                 encoder_scheduler, decoder_scheduler,\n",
    "                                 criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9186a25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.25186823554661,\n",
       " 8.835960566479226,\n",
       " 9.20870773066645,\n",
       " 11.140752732235452,\n",
       " 11.940462767559548]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ecada55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = sum(test_losses) / len(test_losses)\n",
    "\n",
    "torch.save({\n",
    "            'epoch': epochs,\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "            'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n",
    "            'decoder_optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "            'criterion': criterion\n",
    "            }, f'./checkpoints/checkpoint_epoch{epochs}_testloss{test_loss:.4f}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe73225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "x = datetime.datetime.now()\n",
    "print(f\"Finished at {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf2900e",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d40013",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optionally load trained model\n",
    "encoder_trained = EncoderRNN(en_lang.n_words, hidden_size).to(device)\n",
    "decoder_trained = DecoderRNN(hidden_size, fr_lang.n_words).to(device)\n",
    "\n",
    "checkpoint = torch.load('./checkpoints/checkpoint_epoch50_testloss2.9368')\n",
    "\n",
    "encoder_trained.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "decoder_trained.load_state_dict(checkpoint['decoder_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45386287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_old(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        print(input_tensor)\n",
    "        \n",
    "        # encoder_hidden = encoder.initHidden(input_tensor.shape[0])\n",
    "        #encoder_hidden = encoder.initHidden(1)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "        decoder_outputs, decoder_hidden, _ = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7679d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, input_tensor, input_lang, output_lang):\n",
    "\n",
    "    # Required for tensor matching.\n",
    "    # Remove to see the results for educational purposes.\n",
    "    max_length=MAX_LENGTH\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Initialize the encoder hidden.\n",
    "        #input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.initHidden(1)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "\n",
    "        # only return the hidden and cell states for the last layer and pass it to the decoder\n",
    "        hn, cn = encoder_hidden\n",
    "        encoder_hn_last_layer = hn[-1].view(1,1,-1)\n",
    "        encoder_cn_last_layer = cn[-1].view(1,1,-1)\n",
    "        encoder_hidden_last = [encoder_hn_last_layer, encoder_cn_last_layer]\n",
    "\n",
    "        decoder_input = torch.tensor([SOS_token], device=device)  # SOS\n",
    "        #encoder_hidden_last = [bridge(item) for item in encoder_hidden_last]\n",
    "        decoder_hidden = encoder_hidden_last\n",
    "\n",
    "        decoded_words = []\n",
    "        # decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            # decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        # return decoded_words, decoder_attentions[:di + 1]\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70017933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly_old(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        print(f\"Testing {i+1} / {n}\")\n",
    "        pair = df_test.sample(1).values.tolist()[0]\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0], en_lang, fr_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38f2b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def SentenceFromTensor(lang, tensor):\n",
    "    indexes = tensor.squeeze()\n",
    "    indexes = indexes.tolist()\n",
    "    return [lang.index2word[index] for index in indexes]\n",
    "\n",
    "def reformat_tensor_mask(tensor):\n",
    "    tensor = tensor.squeeze(dim=1)\n",
    "    tensor = tensor.transpose(1,0)\n",
    "    mask = tensor != 0\n",
    "    return tensor, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dbce0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, input_lang, output_lang, n=batch_size):\n",
    "    example = next(iter(test_loader))\n",
    "    for i in range(n):\n",
    "        #pair = testset[i]['sentence']\n",
    "        #pair = [example[0][i], example[1][i]]\n",
    "        #input_tensor, mask_input = reformat_tensor_mask(pair[:,0,:].view(1,1,-1))\n",
    "        pair = df_test.sample(1).values.tolist()[0]\n",
    "        input_tensor = example[0][i]\n",
    "        input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "        input_tensor = input_tensor[input_tensor != 0]\n",
    "        \n",
    "        #output_tensor, mask_output = reformat_tensor_mask(pair[:,1,:].view(1,1,-1))\n",
    "        output_tensor = example[1][i]\n",
    "        output_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "        output_tensor = output_tensor[output_tensor != 0]\n",
    "        \n",
    "        if device == torch.device(\"cuda\"):\n",
    "            input_tensor = input_tensor.cuda()\n",
    "            output_tensor = output_tensor.cuda()\n",
    "\n",
    "        input_sentence = ' '.join(SentenceFromTensor(input_lang, input_tensor))\n",
    "        output_sentence = ' '.join(SentenceFromTensor(output_lang, output_tensor))\n",
    "        print(f\"Test {i+1}/{n}\")\n",
    "        print('> ', input_sentence)\n",
    "        print('= ', output_sentence)\n",
    "        output_words = evaluate(encoder, decoder, input_tensor, en_lang, fr_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('< ', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aeb12580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1/16\n",
      ">  ms courchesne is currently director general of the montreal symphony orchestra and from to was deputy minister of the department of culture and communications with the government of quebec EOS\n",
      "=  mme courchesne est directrice generale de l orchestre symphonique de montreal et de a a ete sous ministre au ministere de la culture et des communications du gouvernement du quebec EOS\n",
      "<  les activites de recherche et de la facon dont on a la fois les activites de la loi sur les activites de la commission du travail et de la loi sur les langues officielles <EOS>\n",
      "\n",
      "Test 2/16\n",
      ">  the end result is that selection according to merit is in doubt in the outcome of this competition EOS\n",
      "=  le resultat final est que la selection au merite est mise en doute dans le resultat de ce concours EOS\n",
      "<  le present rapport visera a une echelle exacte de la loi sur les jeunes qui sont souvent <EOS>\n",
      "\n",
      "Test 3/16\n",
      ">  in his opinion a process that should take weeks can take months EOS\n",
      "=  l acia s attend a ce que les cinq etablissements restants soient operationnels dans environ six a douze mois EOS\n",
      "<  il est important que les jeunes bars rayes morone saxatilis de facon coherente complete equilibree et fiable <EOS>\n",
      "\n",
      "Test 4/16\n",
      ">  because the announcement date was delayed the communication plan had been scaled back and public relations opportunities missed EOS\n",
      "=  comme la date de l annonce avait ete retardee les objectifs du plan de communications ont ete reduits et on a manque certaines occasions de relations publiques EOS\n",
      "<  les activites de recherche et de la facon dont on a la fois la commission europeenne de la loi sur les langues officielles <EOS>\n",
      "\n",
      "Test 5/16\n",
      ">  appear to be entirely transferable to the present case as universalisation of the livret a implies no change in its tax status EOS\n",
      "=  le raisonnement repose naturellement sur un commissionnement normal pour ce type d activite de distribution voir section le niveau de commissionnement envisageable EOS\n",
      "<  les activites de recherche et de la facon dont on a la fois les activites de la loi sur les jeunes qui sont souvent mentionnees figure <EOS>\n",
      "\n",
      "Test 6/16\n",
      ">  a networked research approach web site s of EOS\n",
      "=  une approche en matiere de rechereche en reseau site web de EOS\n",
      "<  le present rapport visera a determiner dans le cadre du projet <EOS>\n",
      "\n",
      "Test 7/16\n",
      ">  many many do EOS\n",
      "=  mais elles sont tres tres nombreuses a avoir ce qu il faut EOS\n",
      "<  le refondre <EOS>\n",
      "\n",
      "Test 8/16\n",
      ">  however phosphorus can act as a nutrient that supports the growth of aquatic vegetation EOS\n",
      "=  cependant le phosphore peut etre utilise comme nutriment par les especes vegetales aquatiques et en favoriser la croissance EOS\n",
      "<  il y a pas de plus de millions de dollars americains et de nouveaux secteurs de la loi sur les jeunes meres <EOS>\n",
      "\n",
      "Test 9/16\n",
      ">  the catholic practice of using incense is based on both the bible and long christian tradition EOS\n",
      "=  la pratique religieuse catholique de l utilisation de l encens repose sur la bible et sur une longue tradition chretienne EOS\n",
      "<  le present rapport visera a une echelle exacte de la loi sur les activites de la loi sur les annees <EOS>\n",
      "\n",
      "Test 10/16\n",
      ">  the rhetoric and reality of corporate tax cuts http www caw ca visual printlibrary speeches briefs briefs protestingtoomuch pdf EOS\n",
      "=  the rhetoric and reality of corporate tax cuts www caw ca visual printlibrary speeches briefs briefs protestingtoomuch pdf EOS\n",
      "<  le present rapport visera a une echelle exacte de la loi sur les jeunes qui sont souvent mentionnees figure <EOS>\n",
      "\n",
      "Test 11/16\n",
      ">  the first three years of the erf should enable these member states to develop actions to improve their administrative capabilities with regard to the asylum procedures EOS\n",
      "=  nouveaux etats membres EOS\n",
      "<  le present rapport visera a une echelle exacte de la loi sur les jeunes qui sont souvent associees a l information sur le rendement de la loi sur les jeunes meres <EOS>\n",
      "\n",
      "Test 12/16\n",
      ">  no one s saying you need to stay off the internet to ward off data thieves but you should keep the following in mind when you re online EOS\n",
      "=  il ne s agit pas de renoncer a internet pour eviter de devenir victime de vol d identite mais lorsque vous naviguez en ligne prenez soins de respecter les consignes suivantes EOS\n",
      "<  les activites de recherche et de la facon dont on a la fois les activites de la loi sur les jeunes qui sont souvent mentionnees dans les jeunes qui est tombee de facon coherente complete\n",
      "\n",
      "Test 13/16\n",
      ">  such research could also examine the attitudes and beliefs of students who have a family member or who know someone else who has experienced a smoking related health problem EOS\n",
      "=  ces recherches pourraient aussi examiner les attitudes et les opinions des eleves dont un membre de la famille ou une connaissance a eu un probleme de sante lie au tabagisme EOS\n",
      "<  les activites de recherche et de la facon dont on a la fois les activites de la loi sur les jeunes qui sont souvent mentionnees dans les jeunes qui est tombee de facon coherente complete\n",
      "\n",
      "Test 14/16\n",
      ">  polling day n e a s EOS\n",
      "=  jour du scrutin l e n par EOS\n",
      "<  mots cles esters de thiols insatures reaction du wadsworth emmons <EOS>\n",
      "\n",
      "Test 15/16\n",
      ">  article any specific terms not provided for in the above conditions and or any amendment to the same shall be specified in the annex to the contract EOS\n",
      "=  article toute modalite particuliere non prevue et ou toute modification des conditions stipulees ci dessus sont specifiees a l annexe du present contrat EOS\n",
      "<  les activites de recherche et de la facon dont on a la fois les activites de la loi sur les jeunes qui sont souvent mentionnees dans le cadre du projet <EOS>\n",
      "\n",
      "Test 16/16\n",
      ">  some recommendations may be difficult to accomplish without additional resources EOS\n",
      "=  le rendement de la dpbtg a flechi legerement EOS\n",
      "<  le present rapport visera a une echelle exacte de la loi sur les jeunes meres <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder, en_lang, fr_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6be49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
