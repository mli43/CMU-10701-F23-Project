{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1cf2774",
   "metadata": {},
   "source": [
    "# Reference: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954c4a0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optim\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\__init__.py:1382\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _disable_dynamo\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;66;03m# Import interface functions defined in Python\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m \n\u001b[0;32m   1381\u001b[0m \u001b[38;5;66;03m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[1;32m-> 1382\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;66;03m# Remove unnecessary members\u001b[39;00m\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _StorageBase\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\functional.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _add_docstr\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lowrank\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m svd_lowrank, pca_lowrank\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n\u001b[0;32m     11\u001b[0m     handle_torch_function)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\nn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[0;32m      4\u001b[0m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[0;32m      5\u001b[0m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Identity, Linear, Bilinear, LazyLinear\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1d, Conv2d, Conv3d, \\\n\u001b[0;32m      4\u001b[0m     ConvTranspose1d, ConvTranspose2d, ConvTranspose3d, \\\n\u001b[0;32m      5\u001b[0m     LazyConv1d, LazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d, LazyConvTranspose3d\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Threshold, ReLU, Hardtanh, ReLU6, Sigmoid, Tanh, \\\n\u001b[0;32m      7\u001b[0m     Softmax, Softmax2d, LogSoftmax, ELU, SELU, CELU, GELU, Hardshrink, LeakyReLU, LogSigmoid, \\\n\u001b[0;32m      8\u001b[0m     Softplus, Softshrink, MultiheadAttention, PReLU, Softsign, Softmin, Tanhshrink, RReLU, GLU, \\\n\u001b[0;32m      9\u001b[0m     Hardsigmoid, Hardswish, SiLU, Mish\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parameter, UninitializedParameter\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\nn\\functional.py:20\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# The JIT doesn't understand Union, nor torch.dtype here\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     DType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_jit_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m boolean_dispatch, _overload, BroadcastingList1, BroadcastingList2, BroadcastingList3\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n\u001b[0;32m     23\u001b[0m     handle_torch_function)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _reduction \u001b[38;5;28;01mas\u001b[39;00m _Reduction\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\_jit_internal.py:42\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# This is needed. `torch._jit_internal` is imported before `torch.distributed.__init__`.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Explicitly ask to import `torch.distributed.__init__` first.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Otherwise, \"AttributeError: module 'torch' has no attribute 'distributed'\" is raised.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrpc\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_mangling\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpackage_mangling\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_awaits\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _Await\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _Await \u001b[38;5;28;01mas\u001b[39;00m CAwait, Future \u001b[38;5;28;01mas\u001b[39;00m CFuture\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\package\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalyze\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mis_from_package\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_from_package\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_structure_representation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Directory\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglob_group\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobGroup\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\package\\analyze\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfind_first_use_of_broken_modules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_first_use_of_broken_modules\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrace_dependencies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trace_dependencies\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\package\\analyze\\find_first_use_of_broken_modules.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackage_exporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PackagingError\n\u001b[0;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfind_first_use_of_broken_modules\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_first_use_of_broken_modules\u001b[39m(exc: PackagingError) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\package\\package_exporter.py:38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stdlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_stdlib_module\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfind_file_dependencies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_files_source_depends_on\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglob_group\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobGroup, GlobPattern\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Importer, OrderedImporter, sys_importer\n\u001b[0;32m     41\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPackagingErrorReason\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmptyMatchError\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPackagingError\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPackageExporter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m ]\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1130\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4591c9",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9def3088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374.3460900783539"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Changing Lives | Changing Society | How It Wor...</td>\n",
       "      <td>Il a transformé notre vie | Il a transformé la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Site map</td>\n",
       "      <td>Plan du site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feedback</td>\n",
       "      <td>Rétroaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credits</td>\n",
       "      <td>Crédits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Français</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  Changing Lives | Changing Society | How It Wor...   \n",
       "1                                           Site map   \n",
       "2                                           Feedback   \n",
       "3                                            Credits   \n",
       "4                                           Français   \n",
       "\n",
       "                                                  fr  \n",
       "0  Il a transformé notre vie | Il a transformé la...  \n",
       "1                                       Plan du site  \n",
       "2                                        Rétroaction  \n",
       "3                                            Crédits  \n",
       "4                                            English  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "if os.path.isfile('./data/valid_subset.csv'):\n",
    "    # cleaned, filtered by length, 10% dataset\n",
    "    df = pd.read_csv('./data/valid_subset.csv', index_col=False)\n",
    "    \n",
    "elif os.path.isfile('./data/valid_cleaned_data.csv'):\n",
    "    # cleaned, filtered by length dataset\n",
    "    df = pd.read_csv('./data/valid_cleaned_data.csv', index_col=False)\n",
    "    \n",
    "elif os.path.isfile('./data/cleaned_data.csv'):\n",
    "    # cleaned dataset\n",
    "    df = pd.read_csv('./data/cleaned_data.csv', index_col=False)\n",
    "else:\n",
    "\n",
    "    df = pd.read_csv('./data/en-fr.csv')\n",
    "'''\n",
    "df = pd.read_csv('./data/en-fr.csv')\n",
    "'''\n",
    "end = time.time()\n",
    "display(end - start)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a32d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488d018",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5554f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67252ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019998550415039062"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean data only if not available    \n",
    "\n",
    "start = time.time()\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "if not os.path.isfile('./data/cleaned_data.csv'):\n",
    "    df['en'] = df['en'].apply(lambda x: normalizeString(str(x)))\n",
    "    df['fr'] = df['fr'].apply(lambda x: normalizeString(str(x)))\n",
    "    df.to_csv('./data/cleaned_data.csv', index=False)\n",
    "    \n",
    "end = time.time()\n",
    "display(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35c2c74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>another easily recognizable form of ar technol...</td>\n",
       "      <td>une autre forme connue de ra est l ecran de vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>however since sao paulo is a big and scattered...</td>\n",
       "      <td>cependant comme sao paulo est une grande ville...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this provision provides among other things tha...</td>\n",
       "      <td>cette provision prevoit notamment qu une deduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where would you expect to find a document that...</td>\n",
       "      <td>ou crois tu que tu trouveras un document qui t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at the request of agency staff additional comm...</td>\n",
       "      <td>a la demande du personnel de l office royal a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146988</th>\n",
       "      <td>it would be most beneficial and effective for ...</td>\n",
       "      <td>il serait tres avantageux et efficace pour le ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146989</th>\n",
       "      <td>cost reductions particular importance shall be...</td>\n",
       "      <td>reductions des couts une importance particulie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146990</th>\n",
       "      <td>this inconsistent approach to marking had sign...</td>\n",
       "      <td>cette methode de cotation non uniforme a eu de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146991</th>\n",
       "      <td>testimony of lgen gervais transcripts vol</td>\n",
       "      <td>temoignage du lgne gervais transcriptions vol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146992</th>\n",
       "      <td>a reinsurance agreement between the fcic and t...</td>\n",
       "      <td>l accord de reassurance entre la fcic et les c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146993 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       en  \\\n",
       "0       another easily recognizable form of ar technol...   \n",
       "1       however since sao paulo is a big and scattered...   \n",
       "2       this provision provides among other things tha...   \n",
       "3       where would you expect to find a document that...   \n",
       "4       at the request of agency staff additional comm...   \n",
       "...                                                   ...   \n",
       "146988  it would be most beneficial and effective for ...   \n",
       "146989  cost reductions particular importance shall be...   \n",
       "146990  this inconsistent approach to marking had sign...   \n",
       "146991          testimony of lgen gervais transcripts vol   \n",
       "146992  a reinsurance agreement between the fcic and t...   \n",
       "\n",
       "                                                       fr  \n",
       "0       une autre forme connue de ra est l ecran de vi...  \n",
       "1       cependant comme sao paulo est une grande ville...  \n",
       "2       cette provision prevoit notamment qu une deduc...  \n",
       "3       ou crois tu que tu trouveras un document qui t...  \n",
       "4       a la demande du personnel de l office royal a ...  \n",
       "...                                                   ...  \n",
       "146988  il serait tres avantageux et efficace pour le ...  \n",
       "146989  reductions des couts une importance particulie...  \n",
       "146990  cette methode de cotation non uniforme a eu de...  \n",
       "146991      temoignage du lgne gervais transcriptions vol  \n",
       "146992  l accord de reassurance entre la fcic et les c...  \n",
       "\n",
       "[146993 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Filter dataset by length\n",
    "MAX_LENGTH = 35\n",
    "\n",
    "if not os.path.isfile('./data/valid_cleaned_data.csv'):\n",
    "    df['en_len'] = df['en'].apply(lambda sent: len(sent.split(\" \")))\n",
    "    df['fr_len'] = df['fr'].apply(lambda sent: len(sent.split(\" \")))\n",
    "\n",
    "    df = df[df['en_len'] < MAX_LENGTH]\n",
    "    df = df[df['fr_len'] < MAX_LENGTH]\n",
    "    \n",
    "    df = df[['en', 'fr']]\n",
    "    \n",
    "    df.to_csv('./data/valid_cleaned_data.csv', index=False)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7757d5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146993 entries, 0 to 146992\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   en      146993 non-null  object\n",
      " 1   fr      146993 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "### Prepare only subset of data\n",
    "frac = 0.1\n",
    "\n",
    "if not os.path.isfile('./data/valid_subset.csv'):\n",
    "    df_subset = df.sample(frac=frac)\n",
    "    df_subset.to_csv('./data/valid_subset.csv', index=False)\n",
    "else:\n",
    "    df_subset = df\n",
    "\n",
    "df_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08378580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [en, fr]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset[df_subset.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b045139",
   "metadata": {},
   "source": [
    "## Create helpers to construct vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bc0fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7e729fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146993"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b50e5",
   "metadata": {},
   "source": [
    "## Preparing Data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "995d6416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146993/146993 [00:05<00:00, 27145.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.978105068206787"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gc.collect()\n",
    "#df_subset = df_subset.sample(frac=0.1)\n",
    "\n",
    "\n",
    "def prepareData(df):\n",
    "    en_lang = Lang('en')\n",
    "    fr_lang = Lang('fr')\n",
    "    \n",
    "    en_vocab = []\n",
    "    fr_vocab = []\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], position=0, leave=True):\n",
    "        en_sent = row['en']\n",
    "        fr_sent = row['fr']\n",
    "        \n",
    "        en_vocab += en_sent.split(\" \")\n",
    "        fr_vocab += fr_sent.split(\" \")\n",
    "        \n",
    "    \n",
    "    # Construct word2index and index2word dicts for the two languages\n",
    "    en_vocab = set(en_vocab)\n",
    "    fr_vocab = set(fr_vocab)\n",
    "    \n",
    "    en_word2index = dict([(word, i+3) for i, word in enumerate(en_vocab)])\n",
    "    fr_word2index = dict([(word, i+3) for i, word in enumerate(fr_vocab)])\n",
    "    \n",
    "    en_index2word = {v: k for k, v in en_word2index.items()}\n",
    "    fr_index2word = {v: k for k, v in fr_word2index.items()}\n",
    "    \n",
    "    en_lang.word2index = en_word2index\n",
    "    fr_lang.word2index = fr_word2index\n",
    "    \n",
    "    en_lang.index2word.update(en_index2word)\n",
    "    fr_lang.index2word.update(fr_index2word)\n",
    "    \n",
    "    en_lang.n_words = len(en_lang.index2word.keys())\n",
    "    fr_lang.n_words = len(fr_lang.index2word.keys())\n",
    "    \n",
    "    return en_lang, fr_lang\n",
    "        \n",
    "\n",
    "start = time.time()\n",
    "en_lang, fr_lang = prepareData(df_subset)\n",
    "end = time.time() \n",
    "display(end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dd28a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>at the request of agency staff additional comm...</td>\n",
       "      <td>a la demande du personnel de l office royal a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at the end of the project these expenses have ...</td>\n",
       "      <td>al finalizar el proyecto hay que comprobar dic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jun sushi richmond total</td>\n",
       "      <td>jun sushi richmond total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>once complete destroy the outdated certificate</td>\n",
       "      <td>delivrer les certificats de statut d indien en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>habitat the pacific great blue heron forages a...</td>\n",
       "      <td>habitat les grands herons du pacifique se nour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29363</th>\n",
       "      <td>small and medium sized enterprises are key to ...</td>\n",
       "      <td>les petites et moyennes entreprises sont au ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29364</th>\n",
       "      <td>home environmental workplace health occupation...</td>\n",
       "      <td>accueil sante de l environnement et du milieu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29365</th>\n",
       "      <td>in addition to federal income tax such individ...</td>\n",
       "      <td>en plus de l impot federal sur le revenu ces p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29366</th>\n",
       "      <td>number of poor children on the rise</td>\n",
       "      <td>le nombre d enfants pauvres est a la hausse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29367</th>\n",
       "      <td>it would be most beneficial and effective for ...</td>\n",
       "      <td>il serait tres avantageux et efficace pour le ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29368 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      en  \\\n",
       "0      at the request of agency staff additional comm...   \n",
       "1      at the end of the project these expenses have ...   \n",
       "2                               jun sushi richmond total   \n",
       "3         once complete destroy the outdated certificate   \n",
       "4      habitat the pacific great blue heron forages a...   \n",
       "...                                                  ...   \n",
       "29363  small and medium sized enterprises are key to ...   \n",
       "29364  home environmental workplace health occupation...   \n",
       "29365  in addition to federal income tax such individ...   \n",
       "29366                number of poor children on the rise   \n",
       "29367  it would be most beneficial and effective for ...   \n",
       "\n",
       "                                                      fr  \n",
       "0      a la demande du personnel de l office royal a ...  \n",
       "1      al finalizar el proyecto hay que comprobar dic...  \n",
       "2                               jun sushi richmond total  \n",
       "3      delivrer les certificats de statut d indien en...  \n",
       "4      habitat les grands herons du pacifique se nour...  \n",
       "...                                                  ...  \n",
       "29363  les petites et moyennes entreprises sont au ca...  \n",
       "29364  accueil sante de l environnement et du milieu ...  \n",
       "29365  en plus de l impot federal sur le revenu ces p...  \n",
       "29366        le nombre d enfants pauvres est a la hausse  \n",
       "29367  il serait tres avantageux et efficace pour le ...  \n",
       "\n",
       "[29368 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_subset.sample(frac=0.8)\n",
    "\n",
    "df_test = pd.concat([df_subset, df_train])\n",
    "df_test.drop_duplicates(keep=False, inplace=True)\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "df_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4de2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def get_dataloader(batch_size, en_lang, fr_lang, df):\n",
    "    \n",
    "    n = len(df)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    \n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=n, position=0, leave=True):\n",
    "        en_sent = row[en_lang.name]\n",
    "        fr_sent = row[fr_lang.name]\n",
    "        \n",
    "        en_ids = indexesFromSentence(en_lang, en_sent)\n",
    "        fr_ids = indexesFromSentence(fr_lang, fr_sent)\n",
    "                \n",
    "        en_ids.append(EOS_token)\n",
    "        fr_ids.append(EOS_token)\n",
    "        \n",
    "        input_ids[idx, :len(en_ids)] = en_ids\n",
    "        target_ids[idx, :len(fr_ids)] = fr_ids\n",
    "        \n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) #, num_workers=8)\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4dd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "887c945e",
   "metadata": {},
   "source": [
    "## Building LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fb4d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.LSTM = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.dropout(self.embedding(input).view(1,1,-1))\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output, hidden = self.LSTM(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        # shape = [num_lstm_layers, batch_size, hidden_size]\n",
    "        encoder_state = [torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
    "                              torch.zeros(1, batch_size, self.hidden_size, device=device)]\n",
    "        \n",
    "        return encoder_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08c0e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.LSTM = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output, (h_n, c_n) = self.LSTM(output, hidden)\n",
    "        output = self.out(output[0])\n",
    "        return output, (h_n, c_n)\n",
    "    \n",
    "    def initHidden(self):\n",
    "        \"\"\"\n",
    "        The spesific type of the hidden layer for the RNN type that is used (LSTM).\n",
    "        :return: All zero hidden state.\n",
    "        \"\"\"\n",
    "        return [torch.zeros(1, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(1, 1, self.hidden_size, device=device)]\n",
    "\n",
    "    def forward_old(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.LSTM(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ab26e7",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd1d7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(input_tensor, target_tensor, encoder, decoder, \n",
    "                encoder_optimizer, decoder_optimizer, criterion, is_training=True):\n",
    "    \n",
    "\n",
    "\n",
    "    batch = input_tensor.shape[0]\n",
    "\n",
    "    encoder_hiddens_last = []\n",
    "    loss = 0\n",
    "\n",
    "    for step_idx in range(batch):\n",
    "        encoder_hidden = encoder.initHidden(1)\n",
    "        input_tensor_step = input_tensor[step_idx, :][input_tensor[step_idx, :] != 0]\n",
    "        input_length = input_tensor_step.size(0)\n",
    "\n",
    "        encoder_outputs = torch.zeros(batch, MAX_LENGTH, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor_step[ei], encoder_hidden)\n",
    "            encoder_outputs[step_idx, ei, :] = encoder_output[0, 0]\n",
    "\n",
    "        # only return the hidden and cell states for the last layer and pass it to the decoder\n",
    "        hn, cn = encoder_hidden\n",
    "        encoder_hn_last_layer = hn[-1].view(1,1,-1)\n",
    "        encoder_cn_last_layer = cn[-1].view(1,1,-1)\n",
    "        encoder_hidden = [encoder_hn_last_layer, encoder_cn_last_layer]\n",
    "\n",
    "        if hn.shape[-1] != hidden_size:\n",
    "            print(hn.size)\n",
    "        if cn.shape[-1] != hidden_size:\n",
    "            print(cn.size)\n",
    "            break\n",
    "        encoder_hiddens_last.append(encoder_hidden)\n",
    "\n",
    "    if hn.shape[-1] != hidden_size:\n",
    "        print(f\"hn size {hn.shape[-1]} != hidden_size {hidden_size} \")\n",
    "        return \n",
    "    if cn.shape[-1] != hidden_size:\n",
    "        print(f\"hn size {cn.shape[-1]} != hidden_size {hidden_size} \")\n",
    "        return \n",
    "        \n",
    "\n",
    "    decoder_input = torch.tensor([SOS_token], device=device)\n",
    "    decoder_hiddens = encoder_hiddens_last\n",
    "    \n",
    "    if is_training:\n",
    "        # Training: target tensor available\n",
    "\n",
    "        for step_idx in range(batch):\n",
    "            # reset the LSTM hidden state. Must be done before you run a new sequence. Otherwise the LSTM will treat\n",
    "            # the new input sequence as a continuation of the previous sequence\n",
    "\n",
    "            target_tensor_step = target_tensor[step_idx, :][target_tensor[step_idx, :] != 0]\n",
    "            target_length = target_tensor_step.size(0)\n",
    "            decoder_hidden = decoder_hiddens[step_idx]\n",
    "\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "                # decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                #     decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "                loss += criterion(decoder_output, target_tensor_step[di].view(1)) / target_length\n",
    "                decoder_input = target_tensor_step[di]  # Teacher forcing\n",
    "    \n",
    "    else:\n",
    "        # Testing: target tensor not available \n",
    "        for step_idx in range(batch):\n",
    "            # reset the LSTM hidden state. Must be done before you run a new sequence. Otherwise the LSTM will treat\n",
    "            # the new input sequence as a continuation of the previous sequence\n",
    "\n",
    "            target_tensor_step = target_tensor[step_idx, :]\n",
    "            target_length = target_tensor_step[target_tensor_step != 0].size(0)\n",
    "            decoder_hidden = decoder_hiddens[step_idx]\n",
    "\n",
    "            for di in range(MAX_LENGTH):\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                loss += criterion(decoder_output, target_tensor_step[di].view(1)) / target_length\n",
    "\n",
    "                if decoder_input.item() == EOS_token:\n",
    "                    break\n",
    "\n",
    "\n",
    "    loss = loss / batch\n",
    "    \n",
    "    return loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ced0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    batch_bar   = tqdm(total=len(dataloader), dynamic_ncols=True, leave=True, position=0, desc='Train')\n",
    "    \n",
    "    for i, data in enumerate(dataloader):\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        input_tensor, target_tensor = data\n",
    "        \n",
    "        if device == torch.device(\"cuda\"):\n",
    "                input_tensor = input_tensor.cuda()\n",
    "                target_tensor = target_tensor.cuda()\n",
    "        \n",
    "        loss = train_batch(input_tensor, target_tensor, encoder, decoder, \n",
    "                encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        batch_bar.set_postfix(train_loss=\"{:.04f}\".format(float(total_loss / (i + 1))))\n",
    "        batch_bar.update()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "learning_rate = 0.01\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "encoder = EncoderRNN(en_lang.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, fr_lang.n_words).to(device)\n",
    "\n",
    "encoder_optimizer = optim.AdamW(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.AdamW(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "encoder_scheduler = optim.lr_scheduler.StepLR(encoder_optimizer, step_size=1, gamma=0.95)\n",
    "decoder_scheduler = optim.lr_scheduler.StepLR(decoder_optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_epoch(train_loader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd7b26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(dataloader, encoder, decoder, criterion):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    total_loss = 0\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, leave=True, position=0, desc='Test')\n",
    "    \n",
    "    for i, data in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            input_tensor, target_tensor = data\n",
    "                    \n",
    "            if device == torch.device(\"cuda\"):\n",
    "                    input_tensor = input_tensor.cuda()\n",
    "                    target_tensor = target_tensor.cuda()\n",
    "\n",
    "            loss = train_batch(input_tensor, target_tensor, encoder, decoder, \n",
    "                    encoder_optimizer, decoder_optimizer, criterion, is_training=False)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        batch_bar.set_postfix(test_loss=\"{:.04f}\".format(float(total_loss / (i + 1))))\n",
    "        batch_bar.update()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9256d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 230/230 [01:07<00:00,  3.39it/s, test_loss=13.4483]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.448340113266655"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "test_epoch(test_loader, encoder, decoder, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c079af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e05e9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, test_dataloader, encoder, decoder, n_epochs,\n",
    "          encoder_optimizer, decoder_optimizer, encoder_scheduler, decoder_scheduler,\n",
    "          criterion):\n",
    "    \n",
    "    start = time.time()\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f\"Epoch {epoch} / {n_epochs}\")\n",
    "        \n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        test_loss = test_epoch(test_dataloader, encoder, decoder, criterion)\n",
    "        \n",
    "        train_losses.append(loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "\n",
    "        encoder_scheduler.step()\n",
    "        decoder_scheduler.step()\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"encoder lr = {encoder_scheduler.get_last_lr()}, decoder lr = {decoder_scheduler.get_last_lr()}\")\n",
    "            print('%s (%d %d%%)' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100))\n",
    "\n",
    "    showPlot(train_losses)\n",
    "    showPlot(test_losses)\n",
    "    \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90ed2a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bac1a7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117594/117594 [00:05<00:00, 19791.85it/s]\n",
      "100%|██████████| 29368/29368 [00:01<00:00, 19352.15it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = get_dataloader(batch_size, en_lang, fr_lang, df_train)\n",
    "test_loader = get_dataloader(batch_size, en_lang, fr_lang, df_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa743bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20007,  6394, 13133, 16539,  2625,     2,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f079f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "learning_rate = 0.01\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "encoder = EncoderRNN(en_lang.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, fr_lang.n_words).to(device)\n",
    "\n",
    "encoder_optimizer = optim.AdamW(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.AdamW(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "encoder_scheduler = optim.lr_scheduler.StepLR(encoder_optimizer, step_size=1, gamma=0.95)\n",
    "decoder_scheduler = optim.lr_scheduler.StepLR(decoder_optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40740989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 10/7350 [00:13<2:47:44,  1.37s/it, train_loss=9.5905]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 3\u001b[0m train_losses, test_losses \u001b[38;5;241m=\u001b[39m train(train_loader, test_loader, encoder, decoder, epochs,\n\u001b[0;32m      4\u001b[0m                                  encoder_optimizer, decoder_optimizer,\n\u001b[0;32m      5\u001b[0m                                  encoder_scheduler, decoder_scheduler,\n\u001b[0;32m      6\u001b[0m                                  criterion)\n",
      "Cell \u001b[1;32mIn[26], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_dataloader, test_dataloader, encoder, decoder, n_epochs, encoder_optimizer, decoder_optimizer, encoder_scheduler, decoder_scheduler, criterion)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0;32m     14\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m test_epoch(test_dataloader, encoder, decoder, criterion)\n\u001b[0;32m     16\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "Cell \u001b[1;32mIn[23], line 23\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[0;32m     18\u001b[0m         target_tensor \u001b[38;5;241m=\u001b[39m target_tensor\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m train_batch(input_tensor, target_tensor, encoder, decoder, \n\u001b[0;32m     21\u001b[0m         encoder_optimizer, decoder_optimizer, criterion)\n\u001b[1;32m---> 23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     25\u001b[0m encoder_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     26\u001b[0m decoder_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\iml\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "train_losses, test_losses = train(train_loader, test_loader, encoder, decoder, epochs,\n",
    "                                 encoder_optimizer, decoder_optimizer,\n",
    "                                 encoder_scheduler, decoder_scheduler,\n",
    "                                 criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9186a25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.25186823554661,\n",
       " 8.835960566479226,\n",
       " 9.20870773066645,\n",
       " 11.140752732235452,\n",
       " 11.940462767559548]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ecada55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = sum(test_losses) / len(test_losses)\n",
    "\n",
    "torch.save({\n",
    "            'epoch': epochs,\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "            'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n",
    "            'decoder_optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "            'criterion': criterion\n",
    "            }, f'./checkpoints/checkpoint_epoch{epochs}_testloss{test_loss:.4f}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe73225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "x = datetime.datetime.now()\n",
    "print(f\"Finished at {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf2900e",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d40013",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optionally load trained model\n",
    "encoder_trained = EncoderRNN(en_lang.n_words, hidden_size).to(device)\n",
    "decoder_trained = DecoderRNN(hidden_size, fr_lang.n_words).to(device)\n",
    "\n",
    "checkpoint = torch.load('./checkpoints/checkpoint_epoch50_testloss2.9368')\n",
    "\n",
    "encoder_trained.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "decoder_trained.load_state_dict(checkpoint['decoder_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45386287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_old(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        print(input_tensor)\n",
    "        \n",
    "        # encoder_hidden = encoder.initHidden(input_tensor.shape[0])\n",
    "        #encoder_hidden = encoder.initHidden(1)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "        decoder_outputs, decoder_hidden, _ = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7679d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, input_tensor, input_lang, output_lang):\n",
    "\n",
    "    # Required for tensor matching.\n",
    "    # Remove to see the results for educational purposes.\n",
    "    max_length=MAX_LENGTH\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Initialize the encoder hidden.\n",
    "        #input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.initHidden(1)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "\n",
    "        # only return the hidden and cell states for the last layer and pass it to the decoder\n",
    "        hn, cn = encoder_hidden\n",
    "        encoder_hn_last_layer = hn[-1].view(1,1,-1)\n",
    "        encoder_cn_last_layer = cn[-1].view(1,1,-1)\n",
    "        encoder_hidden_last = [encoder_hn_last_layer, encoder_cn_last_layer]\n",
    "\n",
    "        decoder_input = torch.tensor([SOS_token], device=device)  # SOS\n",
    "        #encoder_hidden_last = [bridge(item) for item in encoder_hidden_last]\n",
    "        decoder_hidden = encoder_hidden_last\n",
    "\n",
    "        decoded_words = []\n",
    "        # decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            # decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        # return decoded_words, decoder_attentions[:di + 1]\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70017933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly_old(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        print(f\"Testing {i+1} / {n}\")\n",
    "        pair = df_test.sample(1).values.tolist()[0]\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0], en_lang, fr_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38f2b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def SentenceFromTensor(lang, tensor):\n",
    "    indexes = tensor.squeeze()\n",
    "    indexes = indexes.tolist()\n",
    "    return [lang.index2word[index] for index in indexes]\n",
    "\n",
    "def reformat_tensor_mask(tensor):\n",
    "    tensor = tensor.squeeze(dim=1)\n",
    "    tensor = tensor.transpose(1,0)\n",
    "    mask = tensor != 0\n",
    "    return tensor, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dbce0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, input_lang, output_lang, n=batch_size):\n",
    "    example = next(iter(test_loader))\n",
    "    for i in range(n):\n",
    "        #pair = testset[i]['sentence']\n",
    "        #pair = [example[0][i], example[1][i]]\n",
    "        #input_tensor, mask_input = reformat_tensor_mask(pair[:,0,:].view(1,1,-1))\n",
    "        pair = df_test.sample(1).values.tolist()[0]\n",
    "        input_tensor = example[0][i]\n",
    "        input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "        input_tensor = input_tensor[input_tensor != 0]\n",
    "        \n",
    "        #output_tensor, mask_output = reformat_tensor_mask(pair[:,1,:].view(1,1,-1))\n",
    "        output_tensor = example[1][i]\n",
    "        output_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "        output_tensor = output_tensor[output_tensor != 0]\n",
    "        \n",
    "        if device == torch.device(\"cuda\"):\n",
    "            input_tensor = input_tensor.cuda()\n",
    "            output_tensor = output_tensor.cuda()\n",
    "\n",
    "        input_sentence = ' '.join(SentenceFromTensor(input_lang, input_tensor))\n",
    "        output_sentence = ' '.join(SentenceFromTensor(output_lang, output_tensor))\n",
    "        print(f\"Test {i+1}/{n}\")\n",
    "        print('> ', input_sentence)\n",
    "        print('= ', output_sentence)\n",
    "        output_words = evaluate(encoder, decoder, input_tensor, en_lang, fr_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('< ', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aeb12580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1/16\n",
      ">  ms courchesne is currently director general of the montreal symphony orchestra and from to was deputy minister of the department of culture and communications with the government of quebec EOS\n",
      "=  mme courchesne est directrice generale de l orchestre symphonique de montreal et de a a ete sous ministre au ministere de la culture et des communications du gouvernement du quebec EOS\n",
      "<  les activites de recherche et de la facon dont on a la fois les activites de la loi sur les activites de la commission du travail et de la loi sur les langues officielles <EOS>\n",
      "\n",
      "Test 2/16\n",
      ">  the end result is that selection according to merit is in doubt in the outcome of this competition EOS\n",
      "=  le resultat final est que la selection au merite est mise en doute dans le resultat de ce concours EOS\n",
      "<  le present rapport visera a une echelle exacte de la loi sur les jeunes qui sont souvent <EOS>\n",
      "\n",
      "Test 3/16\n",
      ">  in his opinion a process that should take weeks can take months EOS\n",
      "=  l acia s attend a ce que les cinq etablissements restants soient operationnels dans environ six a douze mois EOS\n",
      "<  il est important que les jeunes bars rayes morone saxatilis de facon coherente complete equilibree et fiable <EOS>\n",
      "\n",
      "Test 4/16\n",
      ">  because the announcement date was delayed the communication plan had been scaled back and public relations opportunities missed EOS\n",
      "=  comme la date de l annonce avait ete retardee les objectifs du plan de communications ont ete reduits et on a manque certaines occasions de relations publiques EOS\n",
      "<  les activites de recherche et de la facon dont on a la fois la commission europeenne de la loi sur les langues officielles <EOS>\n",
      "\n",
      "Test 5/16\n",
      ">  appear to be entirely transferable to the present case as universalisation of the livret a implies no change in its tax status EOS\n",
      "=  le raisonnement repose naturellement sur un commissionnement normal pour ce type d activite de distribution voir section le niveau de commissionnement envisageable EOS\n",
      "<  les activites de recherche et de la facon dont on a la fois les activites de la loi sur les jeunes qui sont souvent mentionnees figure <EOS>\n",
      "\n",
      "Test 6/16\n",
      ">  a networked research approach web site s of EOS\n",
      "=  une approche en matiere de rechereche en reseau site web de EOS\n",
      "<  le present rapport visera a determiner dans le cadre du projet <EOS>\n",
      "\n",
      "Test 7/16\n",
      ">  many many do EOS\n",
      "=  mais elles sont tres tres nombreuses a avoir ce qu il faut EOS\n",
      "<  le refondre <EOS>\n",
      "\n",
      "Test 8/16\n",
      ">  however phosphorus can act as a nutrient that supports the growth of aquatic vegetation EOS\n",
      "=  cependant le phosphore peut etre utilise comme nutriment par les especes vegetales aquatiques et en favoriser la croissance EOS\n",
      "<  il y a pas de plus de millions de dollars americains et de nouveaux secteurs de la loi sur les jeunes meres <EOS>\n",
      "\n",
      "Test 9/16\n",
      ">  the catholic practice of using incense is based on both the bible and long christian tradition EOS\n",
      "=  la pratique religieuse catholique de l utilisation de l encens repose sur la bible et sur une longue tradition chretienne EOS\n",
      "<  le present rapport visera a une echelle exacte de la loi sur les activites de la loi sur les annees <EOS>\n",
      "\n",
      "Test 10/16\n",
      ">  the rhetoric and reality of corporate tax cuts http www caw ca visual printlibrary speeches briefs briefs protestingtoomuch pdf EOS\n",
      "=  the rhetoric and reality of corporate tax cuts www caw ca visual printlibrary speeches briefs briefs protestingtoomuch pdf EOS\n",
      "<  le present rapport visera a une echelle exacte de la loi sur les jeunes qui sont souvent mentionnees figure <EOS>\n",
      "\n",
      "Test 11/16\n",
      ">  the first three years of the erf should enable these member states to develop actions to improve their administrative capabilities with regard to the asylum procedures EOS\n",
      "=  nouveaux etats membres EOS\n",
      "<  le present rapport visera a une echelle exacte de la loi sur les jeunes qui sont souvent associees a l information sur le rendement de la loi sur les jeunes meres <EOS>\n",
      "\n",
      "Test 12/16\n",
      ">  no one s saying you need to stay off the internet to ward off data thieves but you should keep the following in mind when you re online EOS\n",
      "=  il ne s agit pas de renoncer a internet pour eviter de devenir victime de vol d identite mais lorsque vous naviguez en ligne prenez soins de respecter les consignes suivantes EOS\n",
      "<  les activites de recherche et de la facon dont on a la fois les activites de la loi sur les jeunes qui sont souvent mentionnees dans les jeunes qui est tombee de facon coherente complete\n",
      "\n",
      "Test 13/16\n",
      ">  such research could also examine the attitudes and beliefs of students who have a family member or who know someone else who has experienced a smoking related health problem EOS\n",
      "=  ces recherches pourraient aussi examiner les attitudes et les opinions des eleves dont un membre de la famille ou une connaissance a eu un probleme de sante lie au tabagisme EOS\n",
      "<  les activites de recherche et de la facon dont on a la fois les activites de la loi sur les jeunes qui sont souvent mentionnees dans les jeunes qui est tombee de facon coherente complete\n",
      "\n",
      "Test 14/16\n",
      ">  polling day n e a s EOS\n",
      "=  jour du scrutin l e n par EOS\n",
      "<  mots cles esters de thiols insatures reaction du wadsworth emmons <EOS>\n",
      "\n",
      "Test 15/16\n",
      ">  article any specific terms not provided for in the above conditions and or any amendment to the same shall be specified in the annex to the contract EOS\n",
      "=  article toute modalite particuliere non prevue et ou toute modification des conditions stipulees ci dessus sont specifiees a l annexe du present contrat EOS\n",
      "<  les activites de recherche et de la facon dont on a la fois les activites de la loi sur les jeunes qui sont souvent mentionnees dans le cadre du projet <EOS>\n",
      "\n",
      "Test 16/16\n",
      ">  some recommendations may be difficult to accomplish without additional resources EOS\n",
      "=  le rendement de la dpbtg a flechi legerement EOS\n",
      "<  le present rapport visera a une echelle exacte de la loi sur les jeunes meres <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder, en_lang, fr_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6be49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
